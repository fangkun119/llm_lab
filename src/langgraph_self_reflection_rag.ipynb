{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5afcaed0-3d55-4e1f-95d3-c32c751c29d8",
   "metadata": {
    "id": "5afcaed0-3d55-4e1f-95d3-c32c751c29d8"
   },
   "source": [
    "# LangGraph自适应RAG\n",
    "\n",
    "## 1. 介绍\n",
    "\n",
    "自适应 RAG 是一种 RAG 策略，它将 (1) [查询分析](https://blog.langchain.dev/query-construction/) 与 (2) [主动/自我纠正 RAG](https://blog.langchain.dev/agentic-rag-with-langgraph/) 结合起来。\n",
    "\n",
    "这里实现的一个自适应RAG，它能够通过三种途径回答问题：\n",
    "\n",
    "* 无检索，直接回答问题\n",
    "* 网络搜索，回答问题\n",
    "* 查询向量数据库，回答问题\n",
    "\n",
    "它的执行过程如下：\n",
    "\n",
    "* 问题路由：\n",
    "    * web_search - 回答具有时效性问题\n",
    "    * vectorstore - 回答知识库所覆盖的问题\n",
    "    * LLM - 其他问题\n",
    "* 问题回答：其中vectorstore会根据相关性进行文档过滤\n",
    "* 幻觉检测：如果有幻觉，即答案不符合查到的文档或常识(grand truth)，则重新生成答案\n",
    "* 答案检测：如果生成内容不足以回答问提，fall back到web_search重新回答"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259c7e82-0158-4c41-9fdf-59ac84769314",
   "metadata": {},
   "source": [
    "## 2. 准备工作\n",
    "\n",
    "### 2.1 安装依赖"
   ]
  },
  {
   "cell_type": "code",
   "id": "dfa11188-cf97-415f-b2fa-19c1d9713c46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T06:09:14.123748Z",
     "start_time": "2024-08-10T06:09:13.951828Z"
    }
   },
   "source": [
    "with open('./requirements.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        print(line.strip())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "protobuf\n",
      "langchain\n",
      "langchain-openai\n",
      "tiktoken\n",
      "langchainhub\n",
      "chromadb\n",
      "langgraph\n",
      "langchain-community\n",
      "langchain-core\n",
      "zhipuai\n",
      "httpx_sse\n",
      "bs4\n",
      "lxml\n",
      "faiss-cpu\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "41a813c5-0139-46af-830b-704235311817",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T06:09:15.889258Z",
     "start_time": "2024-08-10T06:09:15.885247Z"
    }
   },
   "source": "# ! pip3 install -r ./requirements.txt --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "49671ba5-96f0-4f63-9f2b-a84147bf6cfb",
   "metadata": {},
   "source": [
    "### 2.2 准备API Key\n",
    "\n",
    "获取或购买API Key\n",
    "\n",
    "* ChatGLM: [https://open.bigmodel.cn/](https://open.bigmodel.cn/)\n",
    "* Open AI: [https://api.xty.app/](https://api.xty.app/)\n",
    "* TAVILY: [https://tavily.com/](https://tavily.com/)\n",
    "* KIMI: [https://platform.moonshot.cn/](https://platform.moonshot.cn/)\n",
    "* Langchain (for Langsmith): 见下一小节\n",
    "\n",
    "设置API Key\n",
    "\n",
    "1. 替换`API KEY`的值、然后把下列命令添加到`~/.bash_profile`文件中\n",
    "\n",
    "~~~bash\n",
    "export OPENAI_API_KEY=\"sk-mt...vjl\" \n",
    "export ZHIPU_API_KEY=\"210...w5y\"\n",
    "export TAVILY_API_KEY=\"tvly...E1R\" # free API key with 1000 requests \n",
    "export LANGCHAIN_API_KEY=\"lsv2...599\"\n",
    "export KIMI_API_KEY=\"sk-...h59\"\n",
    "~~~\n",
    "\n",
    "2. 在`shell`中按`Cmd + C`退出jupyter notebook\n",
    "3. 载入`API KEY`然后重启`jupyter nootbook`\n",
    "\n",
    "~~~bash\n",
    "source ~/.bash_profile\n",
    "jupyter notebook \n",
    "~~~\n",
    "\n",
    "详细配置参考[setup.sh](setup.sh)\n",
    "如果使用IDE，则将上述环境变量配置在IDE的运行设置中"
   ]
  },
  {
   "cell_type": "code",
   "id": "95c7cc80-2176-4c93-a650-dd9148e94bb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:09:11.946556Z",
     "start_time": "2024-08-10T10:09:11.941757Z"
    }
   },
   "source": [
    "# 测试API KEY是否已经在环境变量中\n",
    "import os\n",
    "print(f\"ZHIPU_API_KEY\\t: {os.environ['ZHIPU_API_KEY'][:5]}... \")\n",
    "print(f\"OPENAI_API_KEY\\t: {os.environ['OPENAI_API_KEY'][:5]}...\")\n",
    "print(f\"TAVILY_API_KEY\\t: {os.environ['TAVILY_API_KEY'][:5]}...\")\n",
    "print(f\"LANGCHAIN_API_KEY\\t: {os.environ['LANGCHAIN_API_KEY'][:5]}...\")\n",
    "print(f\"KIMI_API_KEY\\t: {os.environ['KIMI_API_KEY'][:5]}...\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZHIPU_API_KEY\t: 210ba... \n",
      "OPENAI_API_KEY\t: sk-mt...\n",
      "TAVILY_API_KEY\t: tvly-...\n",
      "LANGCHAIN_API_KEY\t: lsv2_...\n",
      "KIMI_API_KEY\t: sk-Jb...\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "1f34306c-9140-457a-9fca-f9c91ac1cc62",
   "metadata": {},
   "source": [
    "### 2.3 准备langsmith\n",
    "\n",
    "访问[https://smith.langchain.com/](https://smith.langchain.com/)\n",
    "\n",
    "* 注册账号\n",
    "* 点击`Setting`->`API Key`创建API Key，添加到环境变量中（参考上一小节）\n",
    "* 点击`Projects`->`Create New Project`查看创建Project的代码，主要是设置下面的一组环境变量，包括LANGCHAIN_TRACING_V2、LANGCHAIN_ENDPOINT、LANGCHAIN_API_KEY、LANGCHAIN_PROJECT\n",
    "\n",
    "上述方法，会将日志发送到langchain官网，在官网上进入相对应的project，就能查看tracing数据\n",
    "\n",
    "如果不希望、可以使用官方提供的LangSmith Docker，将日志存储在本地，具体参考：[https://docs.smith.langchain.com/self_hosting/installation](https://docs.smith.langchain.com/self_hosting/installation)"
   ]
  },
  {
   "cell_type": "code",
   "id": "eebe2b40-92c6-4106-a98c-82b249c3032c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:09:14.999700Z",
     "start_time": "2024-08-10T10:09:14.995483Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'false' # set as true to enable tracing\n",
    "os.environ['LANGCHAIN_PROJECT'] = \"investigate_self_correct_rag\"\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = \"https://api.smith.langchain.com\"\n",
    "\n",
    "print(f\"LANGCHAIN_TRACING_V2\\t: {os.environ['LANGCHAIN_TRACING_V2']}\")\n",
    "print(f\"LANGCHAIN_PROJECT\\t: {os.environ['LANGCHAIN_PROJECT']}\")\n",
    "print(f\"LANGCHAIN_API_KEY\\t: {os.environ['LANGCHAIN_API_KEY']}\")\n",
    "print(f\"LANGCHAIN_ENDPOINT\\t: {os.environ['LANGCHAIN_ENDPOINT']}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANGCHAIN_TRACING_V2\t: false\n",
      "LANGCHAIN_PROJECT\t: investigate_self_correct_rag\n",
      "LANGCHAIN_API_KEY\t: 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\n",
      "LANGCHAIN_ENDPOINT\t: https://api.smith.langchain.com\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "9ac1c2cd-81fb-40eb-8ba1-e9197800cba6",
   "metadata": {
    "id": "9ac1c2cd-81fb-40eb-8ba1-e9197800cba6"
   },
   "source": [
    "### 2.3 知识库索引\n",
    "\n",
    "需要安装`zhipuai`和`langchain_community`，安装后重启kernel就可以加载了\n",
    "\n",
    "代码参考文档：\n",
    "\n",
    "* ZhipuAIEmbedding：[https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.zhipuai.ZhipuAIEmbeddings.html](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.zhipuai.ZhipuAIEmbeddings.html#langchain_community.embeddings.zhipuai.ZhipuAIEmbeddings)\n",
    "* Chroma: [https://python.langchain.com/v0.2/docs/integrations/vectorstores/chroma/](https://python.langchain.com/v0.2/docs/integrations/vectorstores/chroma/)\n",
    "* Load Html: [https://python.langchain.com/v0.2/docs/how_to/document_loader_html/](https://python.langchain.com/v0.2/docs/how_to/document_loader_html/)"
   ]
  },
  {
   "cell_type": "code",
   "id": "b224e5ba-50ca-495a-a7fa-0f75a080e03c",
   "metadata": {
    "id": "b224e5ba-50ca-495a-a7fa-0f75a080e03c",
    "ExecuteTime": {
     "end_time": "2024-08-10T10:09:20.018314Z",
     "start_time": "2024-08-10T10:09:19.135116Z"
    }
   },
   "source": [
    "### 建立索引\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from lib.util.LLMUtils import EmbeddingUtil\n",
    "from lib.util.LLMUtils import LLMVendor\n",
    "\n",
    "# 初始化embedding\n",
    "embd = EmbeddingUtil.getModel(LLMVendor.ZHIPU)\n",
    "\n",
    "# 要加载文件的目录\n",
    "file_dir = \"../data/file\"\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "txt_files = [\n",
    "    f\"{file_dir}/2023-03-15-prompt-engineering.txt\",\n",
    "    f\"{file_dir}/2023-06-23-agent.txt\",\n",
    "    f\"{file_dir}/2023-10-25-adv-attack-llm.txt\",\n",
    "]\n",
    "docs = [TextLoader(text_file).load() for text_file in txt_files]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "# 切分\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=512, chunk_overlap=0)\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "len(doc_splits)\n",
    "\n",
    "\n",
    "# 加载文件\n",
    "# from langchain_community.document_loaders import WebBaseLoader\n",
    "# loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "# docs_list = loader.load()\n",
    "\n",
    "# from langchain_community.document_loaders import BSHTMLLoader\n",
    "# backlog_file_dir=\"../backlog/data/file\"\n",
    "# loader = BSHTMLLoader(file_path=f\"{backlog_file_dir}/2023-03-15-prompt-engineering.html\")\n",
    "# docs_list = loader.load()\n",
    "\n",
    "# from langchain_community.document_loaders import MHTMLLoader\n",
    "# backlog_file_dir=\"../backlog/data/file\"\n",
    "# loader = MHTMLLoader(file_path=f\"{backlog_file_dir}/2023-03-15-prompt-engineering.mhtml\")\n",
    "# docs_list = loader.load()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZHIPU_API_KEY\t: 210ba... \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:09:25.641402Z",
     "start_time": "2024-08-10T10:09:25.506135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from lib.util.VectorStoreUtil import VectorStoreUtil\n",
    "from lib.util.VectorStoreUtil import VectorStoreVendor\n",
    "from lib.util.LLMUtils import EmbeddingUtil,LLMVendor\n",
    "\n",
    "# 保存向量数据库dump文件的base目录\n",
    "vectorstore_dump_base_dir=\"../data/vector_store\"\n",
    "\n",
    "# 初始化\n",
    "embd = EmbeddingUtil.getModel(LLMVendor.ZHIPU)\n",
    "vectorstore_wrapper = VectorStoreUtil.create_wrapper(VectorStoreVendor.FAISS)"
   ],
   "id": "a392cecb0578ceda",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZHIPU_API_KEY\t: 210ba... \n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-09T12:40:31.774173Z",
     "start_time": "2024-08-09T12:40:10.715703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 对文档进行embedding，添加到向量数据库，并备份到本地dump文件\n",
    "# vectorstore_wrapper.init_from_docs(docs=doc_splits, embedding=embd)\n",
    "# vectorstore_wrapper.trigger_dump(base_dir=vectorstore_dump_base_dir)"
   ],
   "id": "36e2d1dcd26d6a52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_chunk: 0\n",
      "load_chunk: 1\n",
      "load_chunk: 2\n",
      "load_chunk: 3\n",
      "load_chunk: 4\n",
      "load_chunk: 5\n",
      "load_chunk: 6\n",
      "vector store load complete\n",
      "vector store dump triggered, dir: ../data/vector_store/faiss_dump\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:09:30.684790Z",
     "start_time": "2024-08-10T10:09:30.653632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 从dump文件中加载向量数据库\n",
    "vectorstore_wrapper.init_from_dump(embedding=embd, base_dir=vectorstore_dump_base_dir)\n",
    "\n",
    "# 返回langchain object给其它模块使用\n",
    "vectorstore = vectorstore_wrapper.get_vector_store()\n",
    "retriever = vectorstore.as_retriever()\n",
    "retriever"
   ],
   "id": "3d0e3c13b39ed9b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from ../data/vector_store/faiss_dump\n",
      "load compete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'ZhipuAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x10a35ac30>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "0f52b427-750c-40f8-8893-e9caab3afd8d",
   "metadata": {
    "id": "0f52b427-750c-40f8-8893-e9caab3afd8d"
   },
   "source": [
    "## 3 RAG子模块\n",
    "### 3.1 LLM Query意图分析及路由"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H5CztTqsBOTZ",
   "metadata": {
    "id": "H5CztTqsBOTZ"
   },
   "source": [
    "使用路由器在工具之间进行选择，让大模型根据用户提问来判断使用哪条路由\n",
    "\n",
    "参考文档\n",
    "\n",
    "* ChatGLM用于langchain框架:[https://open.bigmodel.cn/dev/api#langchain_sdk](https://open.bigmodel.cn/dev/api#langchain_sdk)\n",
    "* Langchain tool calling: [https://python.langchain.com/v0.2/docs/how_to/tool_calling/](https://python.langchain.com/v0.2/docs/how_to/tool_calling/)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "bYK-e0diGdPf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bYK-e0diGdPf",
    "outputId": "8b19f0b8-a4aa-4ff9-c967-128de4f20ccf",
    "ExecuteTime": {
     "end_time": "2024-08-10T10:09:48.878053Z",
     "start_time": "2024-08-10T10:09:48.756627Z"
    }
   },
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain.prompts import (ChatPromptTemplate, HumanMessagePromptTemplate)\n",
    "from lib.util.LLMUtils import LLMVendor\n",
    "from lib.util.LLMUtils import ChatModelUtil\n",
    "\n",
    "# 数据模型\n",
    "@tool\n",
    "def web_search(query: str):\n",
    "    \"\"\"The internet. Use web_search for questions that are related to anything else than agents, prompt engineering, and adversarial attacks.\n",
    "\n",
    "    Args: \n",
    "        query: The query to use when searching the internet.\n",
    "    \"\"\"\n",
    "    return\n",
    "\n",
    "@tool\n",
    "def vectorstore(query: str):\n",
    "    \"\"\"A vectorstore containing documents related to agents, prompt engineering, and adversarial attacks. Use the vectorstore for questions on these topics.\n",
    "    \n",
    "    Args:\n",
    "        query: The query to use when searching the vectorstore.\n",
    "    \"\"\"\n",
    "    return\n",
    "\n",
    "# 包含工具使用和序言的 LLM\n",
    "llm = ChatModelUtil.getChatOpenAIModel(vendor=LLMVendor.ZHIPU, temperature=0)\n",
    "structured_llm_router = llm.bind_tools(tools=[web_search, vectorstore])\n",
    "\n",
    "# Prompt\n",
    "route_prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessage(content = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\\n The vectorstore contains documents related to agents, prompt engineering, and adversarial attacks. \\n Use the vectorstore for questions on these topics. Otherwise, use web-search.\"\"\"), \n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_router = route_prompt | structured_llm_router\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "ea2e71af-56ba-42d9-bcf9-5b314befa21e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:09:55.564231Z",
     "start_time": "2024-08-10T10:09:51.399943Z"
    }
   },
   "source": [
    "response = question_router.invoke(\n",
    "    {\"question\": \"Who will the Bears draft first in the NFL draft?\"}\n",
    ")\n",
    "print(response.additional_kwargs[\"tool_calls\"])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 'call_202408101809530993f5092dcd47e3', 'function': {'arguments': '{\"query\": \"Who will the Bears draft first in the NFL draft?\"}', 'name': 'web_search'}, 'type': 'function', 'index': 0}]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "e5a11cd0-3037-4c9c-ae2c-1d4d71922fb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:09:56.587877Z",
     "start_time": "2024-08-10T10:09:55.570237Z"
    }
   },
   "source": [
    "response = question_router.invoke({\"question\": \"What are the types of agent memory?\"})\n",
    "print(response.additional_kwargs[\"tool_calls\"])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 'call_2024081018095675c5f3db2d334e07', 'function': {'arguments': '{\"query\": \"types of agent memory\"}', 'name': 'vectorstore'}, 'type': 'function', 'index': 0}]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "f6cced5c-b118-4707-b5cf-e5cda15c9a9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:09:59.731164Z",
     "start_time": "2024-08-10T10:09:56.590590Z"
    }
   },
   "source": [
    "response = question_router.invoke({\"question\": \"Hi how are you?\"})\n",
    "print(\"tool_calls\" in response.additional_kwargs)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "05B5I-rgk1yO",
   "metadata": {},
   "source": "### 3.2 评价检索道的文档与提问的相关性"
  },
  {
   "cell_type": "code",
   "id": "oaLWNbWxBgjE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oaLWNbWxBgjE",
    "outputId": "8a1a0330-d0c9-4ff8-d0a0-5a8909544de9",
    "ExecuteTime": {
     "end_time": "2024-08-10T10:10:03.504624Z",
     "start_time": "2024-08-10T10:10:03.390703Z"
    }
   },
   "source": [
    "from lib.util.LLMUtils import ChatModelUtil\n",
    "from lib.util.LLMUtils import LLMVendor\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.prompts import (ChatPromptTemplate, HumanMessagePromptTemplate)\n",
    "from lib.util.StructureOutputUtil import YesOrNoUtil\n",
    "\n",
    "# LMM\n",
    "llm = ChatModelUtil.getChatOpenAIModel(LLMVendor.ZHIPU, temperature=0) # model='glm-4-0520', 'glm-4-air'\n",
    "\n",
    "# 结构化输出\n",
    "structured_llm_grader = llm.with_structured_output(\n",
    "    schema=YesOrNoUtil.YesOrNo, method=\"json_mode\", include_raw=False)\n",
    "\n",
    "# 组装成一个Chain\n",
    "grade_prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        SystemMessage(content=f\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n {YesOrNoUtil.json_mode_prompt(yes_means=\"the document is relevant to the question\")}.\"\"\"), \n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\")\n",
    "    ]\n",
    ")\n",
    "retrieval_grader = grade_prompt | structured_llm_grader"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "4edae639ec8ab105",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:10:08.819129Z",
     "start_time": "2024-08-10T10:10:06.292530Z"
    }
   },
   "source": [
    "question = \"introduce prompt engineering\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[0].page_content\n",
    "f'{doc_txt[:500]}...'"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prompt Engineering\\n\\nDate: March 15, 2023 | Estimated Reading Time: 21 min | Author: Lilian Weng\\nTable of Contents\\nPrompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\n\\nThis post only focuses on prompt engineering f...'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "6d86547e-a20a-413f-a919-57ddb0b6bb65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:10:12.450774Z",
     "start_time": "2024-08-10T10:10:08.821252Z"
    }
   },
   "source": [
    "response = retrieval_grader.invoke({\"question\": \"introduce prompt engineering\", \"document\": doc_txt})\n",
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "5551bbbd-8ec6-42b1-a524-d3cdee4c4508",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:10:14.230901Z",
     "start_time": "2024-08-10T10:10:12.453684Z"
    }
   },
   "source": [
    "response = retrieval_grader.invoke({\"question\": \"types of ice cream\", \"document\": doc_txt})\n",
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='no'\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "D43a7vM4EElX",
   "metadata": {
    "id": "D43a7vM4EElX"
   },
   "source": [
    "### 3.3 让LLM回答问题: (1) RAG Chain\n",
    "\n",
    "当拿到向量数据库中的Document，以及用户提问后，就可以用它们来回答问题"
   ]
  },
  {
   "cell_type": "code",
   "id": "BTIUdjRMEq_h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BTIUdjRMEq_h",
    "outputId": "a7288c38-9dad-434f-a7d6-07b7326eb3e3",
    "ExecuteTime": {
     "end_time": "2024-08-10T10:10:18.648683Z",
     "start_time": "2024-08-10T10:10:18.537222Z"
    }
   },
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from lib.util.LLMUtils import ChatModelUtil\n",
    "from langchain_core.messages import SystemMessage,HumanMessage\n",
    "\n",
    "# LLM\n",
    "llm = ChatModelUtil.getChatOpenAIModel(LLMVendor.ZHIPU, temperature=0)\n",
    "\n",
    "# Prompt\n",
    "prompt = lambda x: ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. \\n Answer 'I don't know' if you do not have information to answer this question. \\n Use three sentences maximum and keep the answer concise if you have information to answer this question.\"\"\"),\n",
    "        HumanMessage(\n",
    "            f\"Question: {x['question']} \\nAnswer: \",\n",
    "            additional_kwargs={\"documents\": x[\"documents\"]},\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:10:24.272441Z",
     "start_time": "2024-08-10T10:10:20.443552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test: an answer that covered by document\n",
    "question = \"introduce prompt engineering\"\n",
    "generation = rag_chain.invoke({\"documents\": docs, \"question\": question})\n",
    "print(generation)"
   ],
   "id": "a8863311fee557a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt engineering is the process of crafting and fine-tuning natural language prompts to guide AI models like GPT-3 towards generating desired outputs. It involves understanding the model's capabilities and limitations to elicit more accurate, relevant, and contextually appropriate responses. This technique is crucial for improving the performance and utility of AI in various applications.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:10:27.960971Z",
     "start_time": "2024-08-10T10:10:27.012474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test: an answer that model does not know\n",
    "question = \"What is the job of the person named RJXACAGEDSG LAMUX?\"\n",
    "generation = rag_chain.invoke({\"documents\": docs, \"question\": question})\n",
    "print(generation)"
   ],
   "id": "39c35275c3c1a600",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3.4 让LLM回答问题: (2) Non RAG Chain",
   "id": "9c229c42d4b0625a"
  },
  {
   "cell_type": "code",
   "id": "bc000a7d-84b6-4eb2-88ad-65cc62a44431",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bc000a7d-84b6-4eb2-88ad-65cc62a44431",
    "outputId": "55ddd812-6626-4444-e5f4-53a9911c4d4c",
    "ExecuteTime": {
     "end_time": "2024-08-10T10:10:38.964520Z",
     "start_time": "2024-08-10T10:10:38.852034Z"
    }
   },
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# llm\n",
    "llm = ChatModelUtil.getChatOpenAIModel(LLMVendor.ZHIPU, temperature=0)\n",
    "\n",
    "# prompt\n",
    "prompt = lambda x: ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=\"\"\"You are an assistant for question-answering tasks. Answer the question based upon your knowledge. Use three sentences maximum and keep the answer concise.\"\"\"),\n",
    "        HumanMessage(f\"Question: {x['question']} \\nAnswer: \")\n",
    "    ]\n",
    ")\n",
    "# chain\n",
    "llm_chain = prompt | llm | StrOutputParser()"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:10:44.831292Z",
     "start_time": "2024-08-10T10:10:41.364219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "question = \"Who are you?\"\n",
    "generation = llm_chain.invoke({\"question\": question})\n",
    "print(generation)"
   ],
   "id": "91e6b2b0f2f0caad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an AI assistant designed to provide information and answer questions based on the knowledge programmed into me. I don't have personal experiences or consciousness. How can I assist you today?\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "LiuxmvHfx6sX",
   "metadata": {
    "id": "LiuxmvHfx6sX"
   },
   "source": "### 3.5 幻觉判定"
  },
  {
   "cell_type": "code",
   "id": "y0msuR2DHQkY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y0msuR2DHQkY",
    "outputId": "8e58d1d6-0ba5-4dc3-9fd5-f51a5a15cf35",
    "ExecuteTime": {
     "end_time": "2024-08-10T10:10:49.064436Z",
     "start_time": "2024-08-10T10:10:48.951933Z"
    }
   },
   "source": [
    "from lib.util.StructureOutputUtil import YesOrNoUtil\n",
    "\n",
    "# llm\n",
    "llm = ChatModelUtil.getChatOpenAIModel(LLMVendor.ZHIPU, temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(YesOrNoUtil.YesOrNo, method='json_mode', include_raw=False)\n",
    "\n",
    "# prompt\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=f\"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n Respond using a JSON that contains the key 'binary_score' with the value being 'yes' or 'no' \\n {YesOrNoUtil.json_mode_prompt(yes_means=\"the answer is grounded in / supported by the set of facts.\")}\"\"\"),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"LLM generation: \\n\\n {generation} \\n\\n\"\n",
    "            \"Set of facts: \\n\\n {documents}\"),\n",
    "    ]\n",
    ")\n",
    "reliability_grader = hallucination_prompt | structured_llm_grader"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:10:59.193525Z",
     "start_time": "2024-08-10T10:10:54.623639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test 1: an answer related with the documents\n",
    "response = reliability_grader.invoke({\"documents\": docs, \"generation\": \"Prompt engineering is the process of crafting and fine-tuning natural language prompts to guide AI models like GPT-3 towards generating desired outputs. It involves understanding the model's capabilities and limitations to elicit more accurate, relevant, and contextually appropriate responses. This technique is crucial for improving the performance and utility of AI in various applications.\"})\n",
    "\n",
    "print(f'Reliability: {response}\\n')\n",
    "print(f'Reference documents: \\n {docs[0].to_json().get('kwargs')}\\n'[:300])"
   ],
   "id": "8f111c7c97a1345d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reliability: binary_score='yes'\n",
      "\n",
      "Reference documents: \n",
      " {'metadata': {'source': '../data/file/2023-03-15-prompt-engineering.txt'}, 'page_content': \"Prompt Engineering\\n\\nDate: March 15, 2023 | Estimated Reading Time: 21 min | Author: Lilian Weng\\nTable of Contents\\nPrompt Engineering, also known as In-Context Prompting, refers to m\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:11:05.358046Z",
     "start_time": "2024-08-10T10:11:02.927169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test 2: an answer not related with the documents\n",
    "\n",
    "response = reliability_grader.invoke({\"documents\": docs, \"generation\": \"Prompt engineering is a technique for promoting and motivating subordinates.\"})\n",
    "\n",
    "print(f'Reliability: {response}\\n')\n",
    "print(f'Reference documents: \\n {docs[0].to_json().get('kwargs')}\\n'[:300])"
   ],
   "id": "9f0827d2763ba0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reliability: binary_score='no'\n",
      "\n",
      "Reference documents: \n",
      " {'metadata': {'source': '../data/file/2023-03-15-prompt-engineering.txt'}, 'page_content': \"Prompt Engineering\\n\\nDate: March 15, 2023 | Estimated Reading Time: 21 min | Author: Lilian Weng\\nTable of Contents\\nPrompt Engineering, also known as In-Context Prompting, refers to m\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "JwPCwB_SzMmx",
   "metadata": {
    "id": "JwPCwB_SzMmx"
   },
   "source": "### 3.6 回答质量评价"
  },
  {
   "cell_type": "code",
   "id": "f0c08d14-77a0-4eed-b882-2d636abb22a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f0c08d14-77a0-4eed-b882-2d636abb22a3",
    "outputId": "c567a109-1cca-4961-c0fa-86ed0e70c30c",
    "ExecuteTime": {
     "end_time": "2024-08-10T10:12:09.098519Z",
     "start_time": "2024-08-10T10:12:08.986011Z"
    }
   },
   "source": [
    "from lib.util.StructureOutputUtil import YesOrNoUtil\n",
    "\n",
    "# llm with structure output\n",
    "llm = ChatModelUtil.getChatOpenAIModel(LLMVendor.ZHIPU, temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(YesOrNoUtil.YesOrNo, method='json_mode', include_raw=False)\n",
    "\n",
    "# prompt\n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=f\"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n {YesOrNoUtil.json_mode_prompt(yes_means=\"the answer resolves the question\")}\"\"\"),\n",
    "        HumanMessagePromptTemplate.from_template(\n",
    "            \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# chain\n",
    "answer_relevance_grader = answer_prompt | structured_llm_grader"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:12:18.310169Z",
     "start_time": "2024-08-10T10:12:15.443925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test\n",
    "response=answer_relevance_grader.invoke({\"question\": \"who am i\", \"generation\": \"I am an AI assistant designed to provide information and answer questions based on the knowledge programmed into me. I don't have personal experiences or consciousness. How can I assist you today?\"})\n",
    "response"
   ],
   "id": "ae45dca2d3f307db",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YesOrNo(binary_score='no')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:12:19.400620Z",
     "start_time": "2024-08-10T10:12:18.311733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response=answer_relevance_grader.invoke({\"question\": \"who are u\", \"generation\": \"I am an AI assistant designed to provide information and answer questions based on the knowledge programmed into me. I don't have personal experiences or consciousness. How can I assist you today?\"})\n",
    "response"
   ],
   "id": "9ff0747a64169555",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YesOrNo(binary_score='yes')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:13:56.495729Z",
     "start_time": "2024-08-10T10:13:53.318409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response=answer_relevance_grader.invoke({\"question\": \"introduce prompt engineering\", \"generation\": \"Prompt engineering is the process of crafting and fine-tuning natural language prompts to guide AI models like GPT-3 towards generating desired outputs. It involves understanding the model's capabilities and limitations to elicit more accurate, relevant, and contextually appropriate responses. This technique is crucial for improving the performance and utility of AI in various applications.\"})\n",
    "response"
   ],
   "id": "473bace954b99d4c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YesOrNo(binary_score='yes')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "d07c0b31-b919-4498-869f-9673125c2473",
   "metadata": {
    "id": "d07c0b31-b919-4498-869f-9673125c2473"
   },
   "source": "### 3.7 网页搜索工具"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:14:02.636599Z",
     "start_time": "2024-08-10T10:14:02.570581Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# check API key\n",
    "print(os.environ['TAVILY_API_KEY'][:5])\n",
    "\n",
    "# sample search\n",
    "web_search_tool = TavilySearchResults()"
   ],
   "id": "b055efd0cb698f43",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tvly-\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "01d829bb-1074-4976-b650-ead41dcb9788",
   "metadata": {
    "id": "01d829bb-1074-4976-b650-ead41dcb9788",
    "ExecuteTime": {
     "end_time": "2024-08-04T13:18:31.790885Z",
     "start_time": "2024-08-04T13:18:28.681577Z"
    }
   },
   "source": [
    "# search_result=web_search_tool.invoke(\"Tom and Jerry\")\n",
    "# search_result[0]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tvly-\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'url': 'https://www.facebook.com/WarnerBrosME/videos/tom-jerry-official-trailer/492448011730010/',\n",
       " 'content': 'Tom and Jerry take their cat and mouse game to the big screen. Watch the trailer for the new #TomAndJerryMovie now - coming to theaters 2021.'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "id": "efbbff0e-8843-45bb-b2ff-137bef707ef4",
   "metadata": {
    "id": "efbbff0e-8843-45bb-b2ff-137bef707ef4"
   },
   "source": [
    "## 4 Graph组成\n",
    "\n",
    "以图表形式捕获流程"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4.1 定义Graph State\n",
    "\n",
    "#### (1) graph state"
   ],
   "id": "4f2cf141d52ad073"
  },
  {
   "cell_type": "code",
   "id": "e723fcdb-06e6-402d-912e-899795b78408",
   "metadata": {
    "id": "e723fcdb-06e6-402d-912e-899795b78408",
    "ExecuteTime": {
     "end_time": "2024-08-10T10:14:18.195406Z",
     "start_time": "2024-08-10T10:14:18.191427Z"
    }
   },
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    表示图表的状态。在Graph运行过程中，存储各个Node产生的数据，\n",
    "    - 用作Node的输入和输出。\n",
    "    - 用作Edge的输入，帮助Edge决定路由到哪个Node上\n",
    "\n",
    "    属性：\n",
    "    - question：用户提问\n",
    "    - generation：LLM生成的答案\n",
    "    - documents：从向量数据库中检索到的文档列表\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    documents: List[str]"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "7e2d6c0d-42e8-4399-9751-e315be16607a",
   "metadata": {
    "id": "7e2d6c0d-42e8-4399-9751-e315be16607a"
   },
   "source": [
    "### 4.2 定义Graph Node\n",
    "\n",
    "#### (1) retrieve：查询vector store"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:14:20.453317Z",
     "start_time": "2024-08-10T10:14:20.445643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    检索文档，从向量数据库查询与用户提问有关的内容\n",
    "\n",
    "    参数： state (dict)：当前图形状态\n",
    "    返回： state (dict)：添加到包含已检索文档的状态文档的新键\n",
    "    \"\"\"\n",
    "    print(\"---检索---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # 检索\n",
    "    documents = retriever.invoke(question)\n",
    "    \n",
    "    # 返回更新后的graph state\n",
    "    return {\"documents\": documents, \"question\": question}"
   ],
   "id": "680afca8eb736a38",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### (2) generate: 使用LLM和vector store生成答案",
   "id": "60095aeee514bae1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:14:23.090039Z",
     "start_time": "2024-08-10T10:14:23.086384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate(state):\n",
    "    \"\"\" \n",
    "    使用 vectorstore 生成答案\n",
    "\n",
    "    参数： state (dict)：当前图形状态\n",
    "    返回： state (dict)：添加到状态、generation 的新键，包含 LLM Generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    if not isinstance(documents, list):\n",
    "        documents = [documents]\n",
    "\n",
    "    # RAG 生成\n",
    "    generation = rag_chain.invoke({\"documents\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}"
   ],
   "id": "d87e624a37a9e7ab",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### (3) llm_fallback：只用LLM生成答案",
   "id": "59a08e00691198e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:14:25.896750Z",
     "start_time": "2024-08-10T10:14:25.892964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def llm_fallback(state):\n",
    "    \"\"\"\n",
    "    只使用LLM生成答案\n",
    "\n",
    "    参数：state (dict)：当前图形状态\n",
    "    返回：state (dict)：添加到状态、generation 的新键，其中包含 LLM Generation\n",
    "    \"\"\"\n",
    "    print(\"---LLM Fallback---\")\n",
    "    question = state[\"question\"]\n",
    "    generation = llm_chain.invoke({\"question\": question})\n",
    "    print(f\"question: {question}\")\n",
    "    print(f\"generation: {generation}\")\n",
    "    return {\"question\": question, \"generation\": generation}"
   ],
   "id": "e315f3b6c80e4bf9",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### (4) grade_documents: 检测文档与提问是否相关",
   "id": "dc8f6a78e7c17446"
  },
  {
   "cell_type": "code",
   "id": "b76b5ec3-0720-443d-85b1-c0e79659ca0a",
   "metadata": {
    "id": "b76b5ec3-0720-443d-85b1-c0e79659ca0a",
    "ExecuteTime": {
     "end_time": "2024-08-10T10:14:29.365519Z",
     "start_time": "2024-08-10T10:14:29.360197Z"
    }
   },
   "source": [
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    确定检索到的文档是否与问题相关。\n",
    "\n",
    "    参数：state (dict)：当前图形状态\n",
    "    返回：state (dict)：仅使用经过筛选的相关文档更新文档键\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---检查文件与问题的相关性---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Documents: {documents}\"[:300])\n",
    "\n",
    "    # 为每个文档评分\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"document\": d.page_content}\n",
    "        )\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---打分：文档相关---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---打分：文档不相关---\")\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question}"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### (5) web_search: 网页搜索",
   "id": "1f7e48d43132ce4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:14:32.106596Z",
     "start_time": "2024-08-10T10:14:32.102826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    根据重新表述的问题进行网络搜索。\n",
    "\n",
    "    参数：state (dict)：当前图形状态\n",
    "    返回：state (dict)：使用附加的网络结果更新文档键\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---网络搜索---\")\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # 网络搜索\n",
    "    docs = web_search_tool.invoke({\"query\": question})\n",
    "    print(f\"web_results: {docs}\"[:300])\n",
    "        \n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    return {\"documents\": web_results, \"question\": question}"
   ],
   "id": "cd159773a525dcf9",
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "id": "ooMcwOk--2Aw",
   "metadata": {
    "id": "ooMcwOk--2Aw"
   },
   "source": [
    "### 4.3 定义Graph Edge\n",
    "\n",
    "Edge的输入是Graph State，输出是Node注册在Graph中的Key（4.3小节介绍）"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### (1) route_question: 对提问进行路由\n",
    "\n",
    "判断把问题路由到哪里(web_search/vectorstore/llm)"
   ],
   "id": "791a155440cb813b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:14:37.825168Z",
     "start_time": "2024-08-10T10:14:37.820412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    将问题路由到网络搜索或 RAG。\n",
    "\n",
    "    参数： state (dict)：当前图形状态\n",
    "    返回： str：要调用的下一个节点\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---路由用户问题---\")\n",
    "    question = state[\"question\"]\n",
    "    source = question_router.invoke({\"question\": question})\n",
    "\n",
    "    # 如果没有决定则返回 LLM 或引发错误\n",
    "    if \"tool_calls\" not in source.additional_kwargs:\n",
    "        print(\"---把问题路由到LLM---\")\n",
    "        return \"llm_fallback\"\n",
    "    if len(source.additional_kwargs[\"tool_calls\"]) == 0:\n",
    "        raise \"路由无法确定来源\"\n",
    "\n",
    "    # 选择数据源\n",
    "    datasource = source.additional_kwargs[\"tool_calls\"][0][\"function\"][\"name\"]\n",
    "    if datasource == \"web_search\":\n",
    "        print(\"---把问题路由到网络搜索---\")\n",
    "        return \"web_search\"\n",
    "    elif datasource == \"vectorstore\":\n",
    "        print(\"---把问题路由到数据库---\")\n",
    "        return \"vectorstore\"\n",
    "    else:\n",
    "        print(\"---把问题路由到LLM---\")\n",
    "        return \"vectorstore\""
   ],
   "id": "fa803d5640645d5d",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### (2) decide_to_generate：决定是否生成回答",
   "id": "5fccd488fd7bbae3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-10T10:14:47.186288Z",
     "start_time": "2024-08-10T10:14:47.182204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    确定是否生成答案或重新生成问题。\n",
    "\n",
    "    参数：state (dict)：当前图形状态\n",
    "    返回：str：下一个要调用的节点的二元决策\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---评估已评分文件---\")\n",
    "    question = state[\"question\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if not filtered_documents:\n",
    "        # 所有文档都已过滤 check_relevance\n",
    "        # 我们将重新生成一个新查询\n",
    "        print(\"---所有文件与问题无关，网络搜索---\")\n",
    "        return \"web_search\"\n",
    "    else:\n",
    "        # 我们有相关文件，因此生成答案\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\""
   ],
   "id": "9629e8ba5602c1e1",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### (3) grade_generation_v_documents_and_question：检测文档及回答",
   "id": "c0317b60bbfa9575"
  },
  {
   "cell_type": "code",
   "id": "IDysC03g-47F",
   "metadata": {
    "id": "IDysC03g-47F",
    "ExecuteTime": {
     "end_time": "2024-08-10T10:14:54.965370Z",
     "start_time": "2024-08-10T10:14:54.960273Z"
    }
   },
   "source": [
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    确定生成是否基于文档并回答问题。\n",
    "\n",
    "    参数： state (dict)：当前图形状态\n",
    "    返回： str：下一个要调用的节点的决策\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---检查幻觉---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    print(f\"question: {question}\")\n",
    "    print(f\"generation: {generation}\"[:300])\n",
    "\n",
    "    score = reliability_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    grade = score.binary_score\n",
    "\n",
    "    # 检查幻觉\n",
    "    if grade == \"yes\":\n",
    "        print(\"---生成被文件内容支持---\")\n",
    "        # 检查问答\n",
    "        print(\"---生成评价&问题---\")\n",
    "        score = answer_relevance_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        grade = score.binary_score\n",
    "        if grade == \"yes\":\n",
    "            print(\"---生成解决了问题---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"---生成不能解决问题---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        print(\"---生成不能被文件支持---\")\n",
    "        return \"not supported\""
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "id": "3ab01f36-5628-49ab-bfd3-84bb6f1a1b0f",
   "metadata": {
    "id": "3ab01f36-5628-49ab-bfd3-84bb6f1a1b0f"
   },
   "source": [
    "## 5. 构建和调用Graph\n",
    "\n",
    "### 5.1 构建Graph"
   ]
  },
  {
   "cell_type": "code",
   "id": "67854e07-9293-4c3c-bf9a-bc9a605570ee",
   "metadata": {
    "id": "67854e07-9293-4c3c-bf9a-bc9a605570ee",
    "ExecuteTime": {
     "end_time": "2024-08-10T10:43:25.740832Z",
     "start_time": "2024-08-10T10:43:25.651772Z"
    }
   },
   "source": [
    "import pprint\n",
    "\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# 定义节点并给他们命名（node key）\n",
    "workflow.add_node(\"web_search\", web_search)             # 网络搜索\n",
    "workflow.add_node(\"retrieve\", retrieve)                 # 检索\n",
    "workflow.add_node(\"grade_documents\", grade_documents)   # 给文件打分\n",
    "workflow.add_node(\"generate\", generate)                 # RAG\n",
    "workflow.add_node(\"llm_fallback\", llm_fallback)         # llm\n",
    "\n",
    "# 构建图表\n",
    "workflow.set_conditional_entry_point(\n",
    "    route_question,\n",
    "    {\n",
    "        \"web_search\": \"web_search\",\n",
    "        \"vectorstore\": \"retrieve\",\n",
    "        \"llm_fallback\": \"llm_fallback\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"web_search\", \"generate\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"web_search\": \"web_search\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",  # 幻觉，文档和grand truth不支持\n",
    "        \"not useful\": \"web_search\",   # 生成的答案并不能回答问题\n",
    "        \"useful\": END,\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"llm_fallback\", END)\n",
    "\n",
    "# 编译\n",
    "app = workflow.compile()"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 5.2 测试\n",
    "\n",
    "#### (1) 需要查询网页来回答的问题"
   ],
   "id": "3b1a291084bdae2c"
  },
  {
   "cell_type": "code",
   "id": "29acc541-d726-4b75-84d1-a215845fe88a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29acc541-d726-4b75-84d1-a215845fe88a",
    "outputId": "38e9648d-225a-4f85-c280-80d0b7ac179b",
    "ExecuteTime": {
     "end_time": "2024-08-10T10:43:49.071224Z",
     "start_time": "2024-08-10T10:43:28.611011Z"
    }
   },
   "source": [
    "inputs = {\n",
    "    \"question\": \"Who is the fastest man on earth?\"\n",
    "}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # 节点\n",
    "        pprint.pprint(f\"Node '{key}':\")\n",
    "        # 可选：打印每个节点的完整状态\n",
    "    pprint.pprint(\"\\n---\\n\")\n",
    "\n",
    "# 最终生成\n",
    "pprint.pprint(value[\"generation\"])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---路由用户问题---\n",
      "---把问题路由到网络搜索---\n",
      "---网络搜索---\n",
      "web_results: [{'url': 'https://www.nbcnewyork.com/paris-2024-summer-olympics/worlds-fastest-man-noah-lyles-wins-gold-mens-100m-photo-finish/5669070/', 'content': \"Noah Lyles can claim the title of the 'World's Fastest Man' after winning gold in the men's 100m race in a true photo finish on Sunday. L\n",
      "\"Node 'web_search':\"\n",
      "'\\n---\\n'\n",
      "---GENERATE---\n",
      "---检查幻觉---\n",
      "question: Who is the fastest man on earth?\n",
      "generation: As of my last update, the title of the fastest man on earth is held by Usain Bolt, who set the world record for the 100m sprint in 2009 with a time of 9.58 seconds. However, newer athletes like Yohan Blake and Justin Gatlin have also achieved very fast times. The current world record hol\n",
      "---生成被文件内容支持---\n",
      "---生成评价&问题---\n",
      "---生成解决了问题---\n",
      "\"Node 'generate':\"\n",
      "'\\n---\\n'\n",
      "('As of my last update, the title of the fastest man on earth is held by Usain '\n",
      " 'Bolt, who set the world record for the 100m sprint in 2009 with a time of '\n",
      " '9.58 seconds. However, newer athletes like Yohan Blake and Justin Gatlin '\n",
      " 'have also achieved very fast times. The current world record holder might '\n",
      " 'have changed since my last update.')\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### (2) 需要查向量数据库来回答的问题",
   "id": "e71031150d2660c3"
  },
  {
   "cell_type": "code",
   "id": "69a985dd-03c6-45af-a67b-b15746a2cb5f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "69a985dd-03c6-45af-a67b-b15746a2cb5f",
    "outputId": "d0d4d693-1ab0-43ed-a721-d45446ff1830",
    "ExecuteTime": {
     "end_time": "2024-08-10T10:15:26.573793Z",
     "start_time": "2024-08-10T10:15:02.302654Z"
    }
   },
   "source": [
    "# Run\n",
    "inputs = {\"question\": \"What are the types of agent memory?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # 节点\n",
    "        pprint.pprint(f\"Node '{key}':\")\n",
    "        # 可选：打印每个节点的完整状态\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint.pprint(\"\\n---\\n\")\n",
    "\n",
    "# 最终生成\n",
    "pprint.pprint(value[\"generation\"])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---路由用户问题---\n",
      "---把问题路由到数据库---\n",
      "---检索---\n",
      "\"Node 'retrieve':\"\n",
      "'\\n---\\n'\n",
      "---检查文件与问题的相关性---\n",
      "Question: What are the types of agent memory?\n",
      "Documents: [Document(metadata={'source': '../data/file/2023-06-23-agent.txt'}, page_content='Sensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typicall\n",
      "---打分：文档相关---\n",
      "---打分：文档不相关---\n",
      "---打分：文档相关---\n",
      "---打分：文档相关---\n",
      "---评估已评分文件---\n",
      "---DECISION: GENERATE---\n",
      "\"Node 'grade_documents':\"\n",
      "'\\n---\\n'\n",
      "---GENERATE---\n",
      "---检查幻觉---\n",
      "question: What are the types of agent memory?\n",
      "generation: Agent memory types include sensory memory, short-term memory, and long-term memory. Sensory memory briefly holds sensory information, short-term memory temporarily stores and manipulates information, and long-term memory provides permanent storage of information.\n",
      "---生成被文件内容支持---\n",
      "---生成评价&问题---\n",
      "---生成解决了问题---\n",
      "\"Node 'generate':\"\n",
      "'\\n---\\n'\n",
      "('Agent memory types include sensory memory, short-term memory, and long-term '\n",
      " 'memory. Sensory memory briefly holds sensory information, short-term memory '\n",
      " 'temporarily stores and manipulates information, and long-term memory '\n",
      " 'provides permanent storage of information.')\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### (3) 需要由LLM直接回答的问题",
   "id": "ff38a8b600c3c6a9"
  },
  {
   "cell_type": "code",
   "id": "qPwP_2PNiOjQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qPwP_2PNiOjQ",
    "outputId": "98b70389-0ba3-4a8b-d295-e72749489327",
    "ExecuteTime": {
     "end_time": "2024-08-10T10:15:50.148816Z",
     "start_time": "2024-08-10T10:15:42.796687Z"
    }
   },
   "source": [
    "# Run\n",
    "inputs = {\"question\": \"Hello, who I am talking to?\"}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        # 节点\n",
    "        pprint.pprint(f\"Node '{key}':\")\n",
    "        # 可选：打印每个节点的完整状态\n",
    "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
    "    pprint.pprint(\"\\n---\\n\")\n",
    "\n",
    "# 最终生成\n",
    "pprint.pprint(value[\"generation\"])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---路由用户问题---\n",
      "---把问题路由到LLM---\n",
      "---LLM Fallback---\n",
      "question: Hello, who I am talking to?\n",
      "generation: Hello, you're talking to an AI assistant designed to help with question-answering tasks. How can I assist you today?\n",
      "\"Node 'llm_fallback':\"\n",
      "'\\n---\\n'\n",
      "(\"Hello, you're talking to an AI assistant designed to help with \"\n",
      " 'question-answering tasks. How can I assist you today?')\n"
     ]
    }
   ],
   "execution_count": 39
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
